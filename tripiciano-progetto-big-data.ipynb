{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Setup**","metadata":{}},{"cell_type":"markdown","source":"**Requirements**\n\nPacchetti necessari da installare.","metadata":{}},{"cell_type":"code","source":"! pip install --no-deps keras==2.11.0\n! pip install --no-deps tensorflow==2.11.0\n! pip install keras_applications==1.0.8\n! pip install keras-unet\n! pip install image-classifiers==1.0.0\n! pip install segmentation_models","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:01:44.727409Z","iopub.execute_input":"2023-04-10T23:01:44.728398Z","iopub.status.idle":"2023-04-10T23:02:34.077944Z","shell.execute_reply.started":"2023-04-10T23:01:44.728325Z","shell.execute_reply":"2023-04-10T23:02:34.076485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Imports**\n\nLibrerie base, Keras, TensorFlow e Segmentation Models.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport gc\nimport cv2\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib as mpl\nimport matplotlib.patches as mpatches\nfrom sklearn.model_selection import KFold\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model, save_model\nfrom keras_unet.utils import get_augmented\nfrom keras.optimizers import Adam\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm\nfrom segmentation_models import Unet","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:34.080666Z","iopub.execute_input":"2023-04-10T23:02:34.081077Z","iopub.status.idle":"2023-04-10T23:02:42.900484Z","shell.execute_reply.started":"2023-04-10T23:02:34.081014Z","shell.execute_reply":"2023-04-10T23:02:42.899408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Config**\n\nParametri utili di configurazione.","metadata":{}},{"cell_type":"code","source":"IM_HEIGHT = 320\nIM_WIDTH = 320\n\nBATCH_SIZE = 8\nLR = 0.0001 # 0.00001, 0.001\nEPOCHS = 100 # 50\nN_SPLITS = 10","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:42.902078Z","iopub.execute_input":"2023-04-10T23:02:42.903122Z","iopub.status.idle":"2023-04-10T23:02:42.908269Z","shell.execute_reply.started":"2023-04-10T23:02:42.90308Z","shell.execute_reply":"2023-04-10T23:02:42.907286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Seeds**\n\nSemi di randomizzazione per la riproducibilità.","metadata":{}},{"cell_type":"code","source":"# set numpy, random and TensorFlow seeds \ndef set_seeds(seed=0):\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n\n    \nset_seeds()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:42.910929Z","iopub.execute_input":"2023-04-10T23:02:42.911832Z","iopub.status.idle":"2023-04-10T23:02:42.922111Z","shell.execute_reply.started":"2023-04-10T23:02:42.911794Z","shell.execute_reply":"2023-04-10T23:02:42.921096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Run-Length Encoding (RLE)**\n\nFunzioni per la codifica e decodifica RLE.\n\nRLE è un formato di compressione dei dati senza perdita in cui le sequenze di valori ripetuti vengono sostituite con il valore e un count. \n\nRisulta particolarmente utile per la memorizzazione delle maschere di segmentazione.","metadata":{}},{"cell_type":"code","source":"def rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape, color=1):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:42.923711Z","iopub.execute_input":"2023-04-10T23:02:42.924097Z","iopub.status.idle":"2023-04-10T23:02:42.935167Z","shell.execute_reply.started":"2023-04-10T23:02:42.924038Z","shell.execute_reply":"2023-04-10T23:02:42.934073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"**Data Loading**\n\nCaricamento del CSV contenente il dataset.","metadata":{}},{"cell_type":"code","source":"# load dataset csv as dataframe\ndf = pd.read_csv('/kaggle/input/uw-madison-gi-tract-image-segmentation/train.csv')\n\nprint(\"data_len:\", len(df))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:42.936616Z","iopub.execute_input":"2023-04-10T23:02:42.937118Z","iopub.status.idle":"2023-04-10T23:02:43.51239Z","shell.execute_reply.started":"2023-04-10T23:02:42.937032Z","shell.execute_reply":"2023-04-10T23:02:43.511214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Transformation**\n\nTrasformazione del dataset in un formato più utile all'elaborazione.","metadata":{}},{"cell_type":"code","source":"# transform dataframe\ndef transform(df):\n    \n    # split id in case, day, slice\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    \n    # get path, width and height of dataset images\n    DIR = '/kaggle/input/uw-madison-gi-tract-image-segmentation/train'\n    \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    x = all_images[0].rsplit(\"/\", 4)[0]\n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    \n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    \n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    \n    del x, path_partial_list, tmp_df\n    \n    # create new dataframe \n    # id, segmentation classes (large_boewl, small_bowel, stomach), path, case, day, slice, width, height\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    df_out['large_bowel'] = df['segmentation'][::3].values\n    df_out['small_bowel'] = df['segmentation'][1::3].values\n    df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n    \n    # reorder indexes and fill NaN values with empty values\n    df_out = df_out.reset_index(drop=True)\n    df_out = df_out.fillna('')\n        \n    return df_out\n\n\ndf = transform(df)\n\nprint(\"data_len:\", len(df))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:43.514619Z","iopub.execute_input":"2023-04-10T23:02:43.515003Z","iopub.status.idle":"2023-04-10T23:02:59.057676Z","shell.execute_reply.started":"2023-04-10T23:02:43.514966Z","shell.execute_reply":"2023-04-10T23:02:59.056571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Statistics - Per Class Segmentation Distribution**\n\nDistribuzione delle immagini segmentate per ciascuna classe di segmentazione.","metadata":{}},{"cell_type":"code","source":"# plot per class segmentation distribution\ndef plot_segm_class(df):\n    bar = plt.bar([1,2,3],100*np.mean(df.iloc[:,1:4]!='',axis=0))\n\n    plt.title('Per Class Segmentation Distribution', fontsize=16)\n    \n    plt.xlabel('Class')\n    plt.ylabel('Segmented Images %')\n    \n    plt.xticks([1,2,3])\n\n    labels=[\"large bowel\",\"small bowel\",\"stomach\"]\n\n    for rect, lbl in zip(bar, labels):\n        height = rect.get_height()\n        plt.text(rect.get_x() + rect.get_width()/2, height, lbl + '\\n%.1f %%' % height, ha='center', va='bottom',fontsize=12)\n\n    plt.ylim((0,50))\n\n    plt.show()\n\n    \nplot_segm_class(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:59.059312Z","iopub.execute_input":"2023-04-10T23:02:59.060288Z","iopub.status.idle":"2023-04-10T23:02:59.292698Z","shell.execute_reply.started":"2023-04-10T23:02:59.060256Z","shell.execute_reply":"2023-04-10T23:02:59.291729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Statistics - Per Case Full Segmentation Distribution**\n\nDistribuzione delle immagini totalmente segmentate per ciascun caso in esame.","metadata":{}},{"cell_type":"code","source":"# plot per case full segmentation distribution \ndef plot_segm_case(df):\n    cases = df['case'].unique()\n    n_labels = len(cases)\n    \n    means = np.empty(shape=n_labels)\n    \n    for i in range(n_labels):\n        means[i] = len(df[(df['case'] == cases[i]) & (df.iloc[:,1]!='') & (df.iloc[:,2]!='') & (df.iloc[:,3]!='')])/len(df)\n        \n    plt.figure(figsize=(12,6))\n    bar = plt.bar(np.arange(1,n_labels+1), 100*means)\n\n    plt.title('Per Case Full Segmentation Distribution', fontsize=16)\n    \n    plt.ylabel('Fully Segmented Images %')\n    plt.xlabel('Case')\n    \n    plt.xticks([])\n        \n    plt.show()\n\n    \nplot_segm_case(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:02:59.294249Z","iopub.execute_input":"2023-04-10T23:02:59.294603Z","iopub.status.idle":"2023-04-10T23:03:00.272751Z","shell.execute_reply.started":"2023-04-10T23:02:59.294567Z","shell.execute_reply":"2023-04-10T23:03:00.271798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Statistics - Full Segmentation Distribution**\n\nDistribuzione complessiva delle immagini totalmente segmentate.","metadata":{}},{"cell_type":"code","source":"# plot overall full segmentation distribution \ndef plot_segm(df):\n    bar = plt.bar([1], 100*np.mean((df.iloc[:,1]!='') & (df.iloc[:,2]!='') & (df.iloc[:,3]!=''),axis=0))\n\n    plt.title('Full Segmentation Distribution', fontsize=16)\n    \n    plt.ylabel('Fully Segmented Images %')\n    plt.xlabel('Images')\n    \n    plt.xticks([])\n\n    for rect in bar:\n        height = rect.get_height()\n        plt.text(rect.get_x() + rect.get_width()/2, height, '%.1f %%' % height, ha='center', va='bottom',fontsize=12)\n\n    plt.ylim((0,25))\n\n    plt.show()\n\n    \nplot_segm(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:00.278121Z","iopub.execute_input":"2023-04-10T23:03:00.278429Z","iopub.status.idle":"2023-04-10T23:03:00.458316Z","shell.execute_reply.started":"2023-04-10T23:03:00.278401Z","shell.execute_reply":"2023-04-10T23:03:00.457128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Cleaning**\n\nRimozione di tutti i record di dati relativi a immagini non totalmente segmentate.","metadata":{}},{"cell_type":"code","source":"# filter data containing NaN values and reorder indexes\ndef filter_data(df):\n    df[\"large_bowel\"].replace(\"\", np.nan, inplace=True)\n    df[\"small_bowel\"].replace(\"\", np.nan, inplace=True)\n    df[\"stomach\"].replace(\"\", np.nan, inplace=True)\n    df = df.dropna()\n    df = df.reset_index(drop=True)\n    return df\n\n\ndf = filter_data(df)\n\nprint(\"data_len:\", len(df))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:00.459731Z","iopub.execute_input":"2023-04-10T23:03:00.462105Z","iopub.status.idle":"2023-04-10T23:03:00.506873Z","shell.execute_reply.started":"2023-04-10T23:03:00.46204Z","shell.execute_reply":"2023-04-10T23:03:00.505747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Saving**\n\nSalvataggio del nuovo dataset come CSV e delle relative maschere.","metadata":{}},{"cell_type":"code","source":"# save decoded masks of new dataset\ndef save_masks(df):\n    for index, row in df.iterrows():\n        case = str(row[\"case\"])\n        day = str(row[\"day\"])\n\n        mask_lb = row[\"large_bowel\"]\n        mask_sb = row[\"small_bowel\"]\n        mask_s = row[\"stomach\"]\n\n        h = row[\"height\"]\n        w = row[\"width\"]\n\n        path = \"/kaggle/working/data/processed/masks/\" + case + \"/\" + day + \"/\"\n\n        if (not os.path.exists(path)):\n            os.makedirs(path)\n\n        img_lb = np.uint8(rle_decode(mask_lb, (h,w,1)))\n        img_lb = img_lb.astype(np.float32) *  255.\n        cv2.imwrite(path + \"large_bowel.png\", img_lb)\n        img_sb = np.uint8(rle_decode(mask_sb, (h,w,1)))\n        img_sb = img_sb.astype(np.float32) *  255.\n        cv2.imwrite(path + \"small_bowel.png\", img_sb)\n        img_s = np.uint8(rle_decode(mask_s, (h,w,1)))\n        img_s = img_s.astype(np.float32) *  255.\n        cv2.imwrite(path + \"stomach.png\", img_s)\n\n# save new dataset as csv\n# df.to_csv(\"/kaggle/working/data/processed/data.csv\", index=False)\n\n\n# save_masks(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:00.50828Z","iopub.execute_input":"2023-04-10T23:03:00.509164Z","iopub.status.idle":"2023-04-10T23:03:00.592409Z","shell.execute_reply.started":"2023-04-10T23:03:00.509124Z","shell.execute_reply":"2023-04-10T23:03:00.590756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Generation**\n\nSi utilizza la classe DataGenerator di Keras per la generazione dei dati a batch che consente di risparmiare la memoria impiegata per il caricamento del dataset di immagini.\n\nSono stati distinti due casi di generazione dei dati: \n\n- default/train -> generazione di una batch (size 8) a partire da due minibatch: \n    \n    - train minibatch (size 6): immagini esistenti del train set.\n                         \n    - augmented minibatch (size 2): immagini aumentate ottenute dalla train minibatch.\n                         \n        I dati generati per il training sono incrementati del 33%\n        circa, ottenendo un train set complessivo con il 25% circa di immagini aumentate.\n                         \n- validation/test -> viene generata direttamente una batch (size 8) dal validation/test set.","metadata":{}},{"cell_type":"code","source":"# DataGenerator class\nclass DataGenerator(tf.keras.utils.Sequence):\n    \n    # DataGenerator initialization\n    def __init__(self, df, batch_size = BATCH_SIZE, shuffle=False, subset=\"train\"):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = (int)(batch_size)\n        self.indexes = np.arange(len(df))\n        self.on_epoch_end()\n        \n        if (self.subset == \"train\"):\n            self.augm_minibatch_size = int(np.floor((int)(0.25 * self.batch_size)))\n            self.batch_len = int(np.floor(len(self.df) / (self.batch_size - self.augm_minibatch_size)))\n            self.augm_len = int(np.floor(self.augm_minibatch_size * self.batch_len))\n        else:\n            self.batch_len = int(np.floor(len(self.df) / (int)(self.batch_size)))\n    \n    # BATCH_LEN\n    def __len__(self):\n        return self.batch_len\n            \n    # epoch end event trigger\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    # image and mask batch generation\n    def __getitem__(self, index):\n        \n        # default/train batch case\n        if (self.subset==\"train\"):\n            \n            # create minibatch with 3/4 BATCH_SIZE original samples\n            X = np.empty(((self.batch_size - self.augm_minibatch_size),IM_HEIGHT,IM_WIDTH,3))\n            y = np.empty((((self.batch_size - self.augm_minibatch_size),IM_HEIGHT,IM_WIDTH,3)))\n            \n            indexes = self.indexes[index*((self.batch_size - self.augm_minibatch_size)):(index+1)*((self.batch_size - self.augm_minibatch_size))]\n\n            for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n                w=self.df['width'].iloc[indexes[i]]\n                h=self.df['height'].iloc[indexes[i]]\n\n                img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n                dsize = (IM_HEIGHT,IM_WIDTH)\n                img = cv2.resize(img, dsize)\n                img = img.astype(np.float32) / 255.\n                img = np.expand_dims(img, axis=-1)\n\n                X[i,] = img \n\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (IM_HEIGHT,IM_WIDTH))\n                    y[i,:,:,k] = mask\n\n            # create minibatch with 1/4 BATCH_SIZE augmented samples\n            X_augm, y_augm = self.augment_data(X, y)\n\n            # concat minibatches in a batch with BATCH_SIZE samples\n            X = tf.concat([X, X_augm], axis=0)\n            y = tf.concat([y, y_augm], axis=0)\n            \n            return X, y\n        \n        # validation/test batch case\n        else:\n            \n            # create batch with BATCH_SIZE original samples\n            X = np.empty((self.batch_size,IM_HEIGHT,IM_WIDTH,3))\n            y = np.empty((self.batch_size,IM_HEIGHT,IM_WIDTH,3))\n            \n            indexes = self.indexes[index*(self.batch_size):(index+1)*(self.batch_size)]\n            \n            for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n                w=self.df['width'].iloc[indexes[i]]\n                h=self.df['height'].iloc[indexes[i]]\n\n                img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n                dsize = (IM_HEIGHT,IM_WIDTH)\n                img = cv2.resize(img, dsize)\n                img = img.astype(np.float32) / 255.\n                img = np.expand_dims(img, axis=-1)\n\n                X[i,] = img \n\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (IM_HEIGHT,IM_WIDTH))\n                    y[i,:,:,k] = mask\n                    \n            return X, y\n\n    \n    # data augmentation\n    # augmented data -> 1/3 of train existing samples\n    def augment_data(self, X, y):\n                \n        augm_data = get_augmented(\n            X, y, batch_size=self.augm_minibatch_size,\n            data_gen_args = dict(\n                rotation_range=180,\n                width_shift_range=0.02,\n                height_shift_range=0.02,\n                shear_range=10,\n                zoom_range=0.2,\n                horizontal_flip=False,\n                vertical_flip=True,\n                fill_mode='constant'\n            )\n        )\n        \n        X_augm, y_augm = next(augm_data)\n        \n        return X_augm, y_augm","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:00.594328Z","iopub.execute_input":"2023-04-10T23:03:00.594775Z","iopub.status.idle":"2023-04-10T23:03:00.619261Z","shell.execute_reply.started":"2023-04-10T23:03:00.594735Z","shell.execute_reply":"2023-04-10T23:03:00.617998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Visualization**\n\nVisualizzazione di una batch campione di immagini e relative segmentazioni.","metadata":{}},{"cell_type":"code","source":"# sample plot\ndef plot_segm(img, mask):\n    \n    # labels\n    labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n\n    # label colors\n    colors = ['yellow','green','red']\n\n    # color maps\n    cmap1 = mpl.colors.ListedColormap(colors[0])\n    cmap2 = mpl.colors.ListedColormap(colors[1])\n    cmap3= mpl.colors.ListedColormap(colors[2])\n\n    # patches\n    patches = [mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\n    # grid figure\n    fig = plt.figure(figsize=(12,28)) # figsize=(25,200) for batch_size = 32 \n    grid = gridspec.GridSpec(nrows=BATCH_SIZE, ncols=2)\n    plt.legend(handles=patches, fontsize=6, loc=1, title='Masks', title_fontsize=8)\n    plt.xticks([])\n    plt.yticks([])\n\n    # plot images and segmentations\n    for i in range(BATCH_SIZE):\n        \n        ax0 = fig.add_subplot(grid[i, 0])\n        ax0.imshow(img[i,:,:,0], cmap='bone')\n        \n        mask_lb = mask[i,:,:,0]\n        mask_sb = mask[i,:,:,1]\n        mask_s = mask[i,:,:,2]\n\n        ax1 = fig.add_subplot(grid[i, 1])\n        ax1.imshow(img[i,:,:,0], cmap='bone')\n\n        im1 = ax1.imshow(np.ma.masked_where(mask_lb == False, mask_lb), cmap=cmap1, alpha=1)\n        im2 = ax1.imshow(np.ma.masked_where(mask_sb == False, mask_sb), cmap=cmap2, alpha=1)\n        im3 = ax1.imshow(np.ma.masked_where(mask_s == False, mask_s), cmap=cmap3, alpha=1)\n        \n        for ax in [ax0,ax1]:\n            ax.set_axis_off()\n        \n        for im in [im1,im2,im3]:\n            im.cmap(im.norm(1))\n        \n        if (i==0):\n            ax0.set_title(\"Image\", fontsize=18, weight='bold')\n            ax1.set_title(\"Segmentation\", fontsize=18, weight='bold')\n\n# data generator instance\ndata_gen = DataGenerator(df, shuffle=True)\n\n# get batch sample\nimg, mask = data_gen[0]\n\n\nplot_segm(img, mask)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:00.620765Z","iopub.execute_input":"2023-04-10T23:03:00.621381Z","iopub.status.idle":"2023-04-10T23:03:06.7127Z","shell.execute_reply.started":"2023-04-10T23:03:00.621341Z","shell.execute_reply":"2023-04-10T23:03:06.710819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Splitting**\n\nConsiderando il dataset ottenuto dopo la fase di cleaning, si è scelto di utilizzare uno split **80% train, 10% validation, 10% test**.\n\n(Si esclude in questa fase la generazione di augmented data per il train set)","metadata":{}},{"cell_type":"code","source":"df_train = df.sample(frac=0.8, random_state=0)\ndf_val_test = df.drop(df_train.index)\ndf_val = df_val_test.sample(frac=0.5, random_state=0)\ndf_test = df_val_test.drop(df_val.index)\n\nprint(\"train_len:\", len(df_train))\nprint(\"validation_len:\", len(df_val))\nprint(\"test_len:\", len(df_test))","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:06.713858Z","iopub.execute_input":"2023-04-10T23:03:06.714306Z","iopub.status.idle":"2023-04-10T23:03:06.732583Z","shell.execute_reply.started":"2023-04-10T23:03:06.714256Z","shell.execute_reply":"2023-04-10T23:03:06.731104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Selection**","metadata":{}},{"cell_type":"markdown","source":"**Metrics**\n\nSi sono selezionate due metriche di similarità per la valutazione dell'accuratezza del modello: \n\n- coefficiente di **Dice** -> 2 |A∩B| / (|A|+|B|)\n       \n   Tende a indicare l'accuratezza di segmentazione nel caso medio.\n                               \n- coefficiente di Intersection over Union (**IoU**) -> |A∩B| / |A∪B|\n    \n   Tende a indicare l'accuratezza di segmentazione nel caso peggiore.","metadata":{}},{"cell_type":"code","source":"# Dice coefficent\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# Intersection over Union (IoU) coefficent\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    return K.mean((intersection + smooth) / (union + smooth), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:06.734352Z","iopub.execute_input":"2023-04-10T23:03:06.735096Z","iopub.status.idle":"2023-04-10T23:03:06.744153Z","shell.execute_reply.started":"2023-04-10T23:03:06.735037Z","shell.execute_reply":"2023-04-10T23:03:06.743016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loss**\n\nSi è selezionata una funzione di loss che è combinazione della Binary Cross Entropy (BCE) loss e della Dice loss: \n\n- BCE loss -> similarità di informazione tra le distribuzioni di probabilità dei due set.\n\n- Dice loss -> similarità bit a bit tra i due set.\n    \n    **BCE Dice loss** -> BCE loss + Dice loss\n        \nN.B. La metrica IoU non è utilizzabile per la funzione di loss in quanto non differenziabile.","metadata":{}},{"cell_type":"code","source":"# Dice loss\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\n# Binary cross-entropy (BCE) dice loss\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:06.74628Z","iopub.execute_input":"2023-04-10T23:03:06.746659Z","iopub.status.idle":"2023-04-10T23:03:06.756628Z","shell.execute_reply.started":"2023-04-10T23:03:06.746621Z","shell.execute_reply":"2023-04-10T23:03:06.755486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Definition**\n\nSi è selezionato **U-Net** come modello di deep learning per le sue performance nel campo della segmentazione di immagini mediche. \n\nPer l'encoder di U-Net si sono confrontati due architetture di rete neurale convoluzionale (CNN) preaddestrate su ImageNet: \n\n- VGG16: CNN con 13 layers convoluzionali e 3 layers fully connected.\n    \n- ResNet34: CNN residuale con 33 layers convoluzionali e 1 layer fully connected.\n\n    **ResNet34** ha ottenuto performance lievemente superiori ed è stata quindi selezionata.\n    \n    Nella directory \"kaggle/working/models\" sono presenti entrambe le versioni addestrate con relativa learning history.\n\nSegmentazione multiclasse -> Output con tre mappe di probabilità di segmentazione dei pixel.\n\nMetriche -> coefficienti di Dice e IoU.\n\nLoss -> BCE Dice loss.\n\nOttimizzatore -> Algoritmo adattivo Adam con learning rate iniziale di 10^-4.","metadata":{}},{"cell_type":"code","source":"# enable multiple GPUs use\nstrategy = tf.distribute.MirroredStrategy()\nwith strategy.scope():\n    \n    \"\"\"\"\"\"\"\"\"\n    # *** U-Net_vgg16 ***\n    # define multiclass U-Net model with VGG16 as backbone\n    model = Unet(\n        backbone_name='vgg16', \n        input_shape=(IM_HEIGHT, IM_WIDTH, 3), \n        classes=3, \n        activation='sigmoid', \n        encoder_weights='imagenet')\n    \"\"\"\"\"\"\"\"\"\n    \n    # *** U-Net_resnet34 ***\n    # define multiclass U-Net model with ResNet34 as backbone\n    model = Unet(\n        backbone_name='resnet34',\n        input_shape=(IM_HEIGHT, IM_WIDTH, 3), \n        classes=3, \n        activation='sigmoid', \n        encoder_weights='imagenet')\n    \n    # define custom optimizer, metrics and loss\n    optimizer = Adam(LR)\n    model.compile(\n        optimizer=optimizer, \n        metrics=[dice_coef,iou_coef], \n        loss=bce_dice_loss)\n    \n# show model info\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:06.758697Z","iopub.execute_input":"2023-04-10T23:03:06.75928Z","iopub.status.idle":"2023-04-10T23:03:11.355504Z","shell.execute_reply.started":"2023-04-10T23:03:06.759196Z","shell.execute_reply":"2023-04-10T23:03:11.354672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**K-Fold Cross-validation**\n\nValutazione del modello mediante K-Fold Cross-validation con 10 splits.\n\n(Non è stato possibile eseguire per mancanza di risorse)","metadata":{}},{"cell_type":"code","source":"\"\"\"\"\"\"\"\"\"\n# 10 splits\ncv = KFold(n_splits=N_SPLITS)\n\n# model, loss, dice and iou arrays\nmodels = np.empty(shape=N_SPLITS)\nval_losses = np.empty(shape=N_SPLITS)\nval_dice_coefs = np.empty(shape=N_SPLITS)\nval_iou_coefs = np.empty(shape=N_SPLITS)\n\nfor i, (train_ids, val_ids) in enumerate (cv.split(df_train)):\n    # create train and validation folds\n    df_train_fold = df_train.filter(items = train_ids, axis=0)\n    df_val_fold = df_train.filter(items = val_ids, axis=0)\n    \n    # train and validation generators instance\n    train_gen = DataGenerator(df_train_fold, shuffle=True)\n    val_gen = DataGenerator(df_val_fold, shuffle=True, subset=\"val\")\n    \n    models[i] = model\n    \n    # fit model\n    models[i].fit(\n        x=train_gen,\n        validation_data=val_gen,\n        epochs=EPOCHS)\n    \n    # evaluate model on validation set\n    scores = model[i].evaluate(x=val_gen)\n    \n    # read loss, dice and iou\n    val_losses.append(scores['val_loss'])\n    val_dice_coefs.append(scores['val_dice_coef'])\n    val_iou_coefs.append(scores['val_iou_coef'])\n\n# compute loss, dice and iou means as cross-validation scores\ncv_loss = np.mean(val_losses)\ncv_dice_coef = np.mean(val_dice_coefs)\ncv_iou_coef = np.mean(val_iou_coefs)\n\nprint(\"val_dice scores: \", val_dice_coefs)\nprint(\"val_iou scores: \", val_iou_coefs)\nprint(\"val_loss scores: \", val_losses)\n\nprint(\"cv_dice_coef score: \", cv_dice_coef)\nprint(\"cv_iou_coef score: \", cv_iou_coef)\nprint(\"cv_loss score: \", cv_loss)\n\"\"\"\"\"\"\"\"\"\n\nprint(\"Not enough resources to run cross-validation...\")","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:11.356614Z","iopub.execute_input":"2023-04-10T23:03:11.356977Z","iopub.status.idle":"2023-04-10T23:03:11.36669Z","shell.execute_reply.started":"2023-04-10T23:03:11.35694Z","shell.execute_reply":"2023-04-10T23:03:11.365855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Training**","metadata":{}},{"cell_type":"markdown","source":"**Callbacks**\n\nUtilizzo delle seguenti callbacks per il fitting del modello:\n\n- **ModelCheckpoint**: salvataggio del modello migliore secondo un certo score.\n    \n- **ReduceLROnPlateau**: decay del learning rate se il modello non migliora secondo un certo score dopo un numero prefissato di epoche.\n    \n    Per entrambe le callbacks lo score scelto da monitorare è la validation loss.","metadata":{}},{"cell_type":"code","source":"# ModelCheckpoint callback\nmodel_checkpoint = ModelCheckpoint(\n    filepath=\"/kaggle/working/models/U-Net_resnet34/model.h5\",\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=False,\n    mode='min'\n)\n\n# ReduceLROnPlateau callback\nreduce_lr_on_plateau = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=10, # 5\n    verbose=1,\n    min_delta=0.0001\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:11.367998Z","iopub.execute_input":"2023-04-10T23:03:11.368564Z","iopub.status.idle":"2023-04-10T23:03:11.378938Z","shell.execute_reply.started":"2023-04-10T23:03:11.368524Z","shell.execute_reply":"2023-04-10T23:03:11.378009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fitting**\n\nFitting del modello su 100 epoche.","metadata":{}},{"cell_type":"code","source":"\"\"\"\"\"\"\"\"\"\n# train and validation data generators instance\ntrain_gen = DataGenerator(df_train, shuffle=True, subset=\"train\")\nval_gen = DataGenerator(df_val, shuffle=True, subset=\"validation\")\n\n# garbage collection \ngc.collect()\n\n# fit model\nfit_result = model.fit(\n    x=train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=[reduce_lr_on_plateau, model_checkpoint])\n\"\"\"\"\"\"\"\"\"\n\n# load pretrained model\nmodel = load_model(\n     filepath=\"/kaggle/working/models/U-Net_resnet34/model.h5\", # \".../U-Net_vgg16/model.h5\"\n     custom_objects={'dice_coef':dice_coef,'iou_coef':iou_coef,'bce_dice_loss':bce_dice_loss})","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:11.380494Z","iopub.execute_input":"2023-04-10T23:03:11.380812Z","iopub.status.idle":"2023-04-10T23:03:14.282354Z","shell.execute_reply.started":"2023-04-10T23:03:11.380778Z","shell.execute_reply":"2023-04-10T23:03:14.281312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning Curves**\n\nCurve di apprendimento per train e validation rispetto alla loss e alle metriche.\n\nEpoche trascorse per il raggiungimento del modello migliore e relativi scores.","metadata":{}},{"cell_type":"code","source":"# plot learning curves\ndef learning_plot(history, epochs):\n    \n    plt.figure(figsize=(14,21))\n    \n    # train/validation loss subplot\n    plt.subplot(3,1,1)\n    plt.plot(range(1,epochs+1),history['loss'][0:epochs],label='Train_Loss')\n    plt.plot(range(1,epochs+1),history['val_loss'][0:epochs],label='Val_loss')\n    plt.title('LOSS')\n    plt.xlabel('Epoch')\n    plt.ylabel('loss')\n    plt.legend()\n\n    # train/validation dice subplot\n    plt.subplot(3,1,2)\n    plt.plot(range(1,epochs+1),history['dice_coef'][0:epochs],label='Train_dice_coef')\n    plt.plot(range(1,epochs+1),history['val_dice_coef'][0:epochs],label='Val_dice_coef')\n    plt.title('DICE')\n    plt.xlabel('Epoch') \n    plt.ylabel('dice_coef')\n    plt.legend()\n\n    # train/validation iou subplot\n    plt.subplot(3,1,3)\n    plt.plot(range(1,epochs+1),history['iou_coef'][0:epochs],label='Train_iou_coef')\n    plt.plot(range(1,epochs+1),history['val_iou_coef'][0:epochs],label='Val_iou_coef')\n    plt.title('IOU')\n    plt.xlabel('Epoch')\n    plt.ylabel('iou_coef')\n    plt.legend()\n\n    plt.show()\n\n\"\"\"\"\"\"\"\"\"\n# history dataframe\nhistory_df = pd.DataFrame(fit_result.history)\n\n# save history dataframe as csv\nhistory_df.to_csv(\"/kaggle/working/models/U-Net_resnet34/history.csv\") # \".../U-Net_vgg16/history.csv\"\n\"\"\"\"\"\"\"\"\"\n\n# load history csv as dataframe\nhistory_df = pd.read_csv(\"/kaggle/working/models/U-Net_resnet34/history.csv\") # \".../U-Net_vgg16/history.csv\"\n\n# MODEL CHECKPOINT EPOCHS\nmcp_epochs = history_df[\"val_loss\"].idxmin() + 1\nprint(\"MODEL CHECKPOINT EPOCHS:\", mcp_epochs)\n\nprint()\n\n# *** TRAIN SCORES ***\nprint(\"TRAIN SCORES\")\nprint(\"train_loss: %.4f\" % history_df[\"loss\"][mcp_epochs-1])\nprint(\"train_dice_coef: %.4f\" % history_df[\"dice_coef\"][mcp_epochs-1])\nprint(\"train_iou_coef: %.4f\" % history_df[\"iou_coef\"][mcp_epochs])\n\nprint()\n\n# *** VALIDATION SCORES ***\nprint(\"VALIDATION SCORES\")\nprint(\"val_loss: %.4f\" % history_df[\"val_loss\"][mcp_epochs-1])\nprint(\"val_dice_coef: %.4f\" % history_df[\"val_dice_coef\"][mcp_epochs-1])\nprint(\"val_iou_coef: %.4f\" % history_df[\"val_iou_coef\"][mcp_epochs-1])\n\nprint()\n\n\nlearning_plot(history_df, mcp_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:14.284289Z","iopub.execute_input":"2023-04-10T23:03:14.284657Z","iopub.status.idle":"2023-04-10T23:03:14.878885Z","shell.execute_reply.started":"2023-04-10T23:03:14.284619Z","shell.execute_reply":"2023-04-10T23:03:14.877761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Testing**","metadata":{}},{"cell_type":"markdown","source":"**Prediction**\n\nCalcolo predizioni sul test set e conversione delle mappe di probabilità a immagini binarie. \n\nVisualizzazione di una batch campione di ground truth e di predizione delle segmentazioni. ","metadata":{}},{"cell_type":"code","source":"# prediction plot\ndef plot_pred_segm(img, mask, pred):\n    \n    # labels\n    labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n\n    # label colors\n    colors = ['yellow','green','red']\n\n    # color maps\n    cmap1 = mpl.colors.ListedColormap(colors[0])\n    cmap2 = mpl.colors.ListedColormap(colors[1])\n    cmap3= mpl.colors.ListedColormap(colors[2])\n\n    # patches\n    patches = [mpatches.Patch(color=colors[i], label=f\"{labels[i]}\") for i in range(len(labels))]\n\n    # grid figure\n    fig = plt.figure(figsize=(12,28))\n    grid = gridspec.GridSpec(nrows=BATCH_SIZE, ncols=2)\n    plt.legend(handles=patches, fontsize=6, loc=1, title='Masks', title_fontsize=8)\n    plt.xticks([])\n    plt.yticks([])\n\n    # plot ground truth and predicted segmentations\n    for i in range(BATCH_SIZE):\n        \n        mask_lb = mask[i,:,:,0]\n        mask_sb = mask[i,:,:,1]\n        mask_s = mask[i,:,:,2]\n\n        ax0 = fig.add_subplot(grid[i, 0])\n        ax0.imshow(img[i,:,:,0], cmap='bone')\n\n        im1 = ax0.imshow(np.ma.masked_where(mask_lb == False, mask_lb), cmap=cmap1, alpha=1)\n        im2 = ax0.imshow(np.ma.masked_where(mask_sb == False, mask_sb), cmap=cmap2, alpha=1)\n        im3 = ax0.imshow(np.ma.masked_where(mask_s == False, mask_s), cmap=cmap3, alpha=1)\n            \n        pred_lb = pred[i,:,:,0]\n        pred_sb = pred[i,:,:,1]\n        pred_s = pred[i,:,:,2]\n\n        ax1 = fig.add_subplot(grid[i, 1])\n        ax1.imshow(img[i,:,:,0], cmap='bone')\n        \n        im4 = ax1.imshow(np.ma.masked_where(pred_lb == False, pred_lb), cmap=cmap1, alpha=1)\n        im5 = ax1.imshow(np.ma.masked_where(pred_sb == False, pred_sb), cmap=cmap2, alpha=1)\n        im6 = ax1.imshow(np.ma.masked_where(pred_s == False, pred_s), cmap=cmap3, alpha=1)\n        \n        for ax in [ax0,ax1]:\n            ax.set_axis_off()\n        \n        for im in [im1,im2,im3,im4,im5,im6]:\n            im.cmap(im.norm(1))\n            \n        if (i==0):\n            ax0.set_title(\"Ground Truth\", fontsize=18, weight='bold')\n            ax1.set_title(\"Prediction\", fontsize=18, weight='bold')\n            \n# test data generator instance \ntest_gen = DataGenerator(df_test, shuffle=True, subset=\"test\")\n\n# get test batch sample\nimg, mask = test_gen[0]\n\n# predict on test set\npreds = model.predict(x=test_gen, verbose=1)\n\n# convert pixel probability maps to binary image\npreds = (preds > 0.5).astype(np.float32)\n\n# prediction batch sample\npred = preds[0:BATCH_SIZE]\n\n\nplot_pred_segm(img, mask, pred)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:14.880887Z","iopub.execute_input":"2023-04-10T23:03:14.881559Z","iopub.status.idle":"2023-04-10T23:03:30.593356Z","shell.execute_reply.started":"2023-04-10T23:03:14.881518Z","shell.execute_reply":"2023-04-10T23:03:30.592472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Performance**\n\nTest scores per la valutazione delle performance del modello.","metadata":{}},{"cell_type":"code","source":"# evaluate model on test set\neval_result = model.evaluate(x=test_gen,verbose=1)\n\n# *** TEST SCORES ***\nprint(\"TEST SCORES\")\nprint(\"test_loss: %.4f\" % eval_result[0])\nprint(\"test_dice_coef: %.4f\" % eval_result[1])\nprint(\"test_iou_coef: %.4f\" % eval_result[2])","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:04:35.74111Z","iopub.execute_input":"2023-04-10T23:04:35.741787Z","iopub.status.idle":"2023-04-10T23:04:41.055232Z","shell.execute_reply.started":"2023-04-10T23:04:35.741739Z","shell.execute_reply":"2023-04-10T23:04:41.054107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Submission**\n\nSottomissione del CSV contenente le predizioni calcolate sul test set.","metadata":{}},{"cell_type":"code","source":"# create, fill and save submission with predictions \ndef pred_submit(ids, preds):\n\n    # load submission template csv as dataframe\n    submission_df = pd.read_csv(\"/kaggle/input/uw-madison-gi-tract-image-segmentation/sample_submission.csv\")\n\n    # split predictions per classes\n    preds_lb = preds[:,:,:,0]\n    preds_sb = preds[:,:,:,1]\n    preds_s = preds[:,:,:,2]\n\n    for i in range(len(preds)):\n\n        # create rows\n        row_lb = [ids.iloc[i], 'large_bowel', rle_encode(preds_lb[i])]\n        row_sb = [ids.iloc[i], 'small_bowel', rle_encode(preds_sb[i])]\n        row_s = [ids.iloc[i], 'stomach', rle_encode(preds_s[i])]\n\n        # append rows to dataframe\n        submission_df.loc[len(submission_df)] = row_lb\n        submission_df.loc[len(submission_df)] = row_sb\n        submission_df.loc[len(submission_df)] = row_s\n    \n    # save dataframe as csv\n    submission_df.to_csv(\"/kaggle/working/sample_submission.csv\")\n    \n    \n# pred_submit(df_test['id'], preds)\n\n# load submission csv as dataframe\nsubmission_df = pd.read_csv(\"/kaggle/working/sample_submission.csv\")\n\nprint(\"submission_len:\", len(submission_df))\nsubmission_df[['id','class','predicted']].head()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T23:03:36.917088Z","iopub.execute_input":"2023-04-10T23:03:36.917485Z","iopub.status.idle":"2023-04-10T23:03:38.97924Z","shell.execute_reply.started":"2023-04-10T23:03:36.917445Z","shell.execute_reply":"2023-04-10T23:03:38.978134Z"},"trusted":true},"execution_count":null,"outputs":[]}]}